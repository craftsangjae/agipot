{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e93f7e6-3f14-4dee-aee4-8454b7fb1fb8",
   "metadata": {},
   "source": [
    "# LLM Agent를 만드는 여정 (1) LLM의 답변을 정형화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda6568-f2d7-4173-bef1-ad5635c7d4ca",
   "metadata": {},
   "source": [
    "## 들어가기에 앞서 \n",
    "\n",
    "프로그래머로서, GPT o1은 충격적이었습니다. GPT o1와 [Cursor](https://www.cursor.com/)의 사용법만 배운 채로, 기획자 친구가 1시간도 안되는 시간 안에 IOS 앱을 빌드하고 실행하는 것을 성공해냈습니다. 이 모습을 보며 \"프로그램을 작성한다\"라는 일은 몇년 내로 \"엑셀 다룰 줄 알아요\"같은, 그것만으로는 먹고 살지 못하는 능력으로 자리잡을 것이라 생각이 들었습니다. 친구와 저는 카페에서 \"이제 개발하는 것은 옛날 계산기 나오기 전에 주판을 튀기는 것과 같은 거야\"라고 얘기 나눴습니다.\n",
    "\n",
    "지금, 당장, 가장 필요한 일은 무엇일까. 저는 GPT의 잠재력을 끌어내기 위해, GPT에게 눈(Perception)과 손(Action)을 달아주는 것이라 생각했습니다. \n",
    "\n",
    "지금, 당장, 가장, 필요한 기술적 역량은 \"GPT의 강력한 사고하는 능력을 어떻게 끌어낼 것인가\"이라 바라보고 있습니다. 단순히 Text를 주고 받는 LLM에서 벗어나서, 직접 행동으로 옮길 수 있는 능력을 만들어내야 합니다. GPT가 자율적으로 우리를 도와줄 수 있는 시스템, 즉 AI Agent를 만들어 내는 것이 필수라 생각했습니다. 지금 글을 쓰는 이 순간에는 어떻게 만들어야 할지 잘 모르겠어요. 만들어 가는 과정에서 얻은 지식들을 하나씩 정리하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a01b6b-20ca-4d81-bb2c-f80b68e14cd5",
   "metadata": {},
   "source": [
    "### 시리즈 목표 : 나를 위한 AI Agent 만들기\n",
    "\n",
    "<img src=\"../resources/assets/huggingface.png\" width=\"50%\"/>\n",
    "\n",
    "구체적으로는 좀 더 자극적이게 \"나에게 필요한 AI 서비스를 찾고, 만들어주는 AI Agent\"를 만들어 보고자 합니다. 대표적인 AI 모델 플랫폼인 [Huggingface](https://huggingface.co/)는 2024년 10월 기준 99만개에 달하는 AI 모델이 존재합니다. 하지만 여기에서 우리에게 딱 필요한 모델을 찾는 것은 쉽지 않습니다. 여기서 필요한 모델을 찾아, 우리에게 필요한 형태로 가공하는 역할을 수행하는 AI 서비스를 만들어 보고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1231d48-2fb9-4ca4-9f67-35793da673a2",
   "metadata": {},
   "source": [
    "### 구축 환경\n",
    "\n",
    "저에게 친숙하고 LLM 생태계에서도 가장 널리 사용하는 도구들을 선택했습니다.\n",
    "\n",
    "- Python3 \n",
    "- Jupyter Notebook\n",
    "- Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f83d6-875c-43d5-ba1a-75b1d38e7223",
   "metadata": {},
   "source": [
    "## 오늘의 목표 : LLM의 TEXT 답변을 정형화하기 \n",
    "\n",
    "\n",
    "이 시리즈의 첫 번째 글로, 프롬프트 템플릿(PromptTemplate)과 출력 파서(OutputParser)을 통해, 어떻게 Langchain으로 프롬프트 개발을 편리하게 할 수 있는지를 설명하겠습니다.\n",
    "\n",
    "LLM은 단순히 Text를 반환하는 함수입니다. 이런 LLM이 저 대신 카카오T를 부르고, 쿠팡에서 주문하고, 코드를 작성하기 위해서는, Text가 아니라 Action을 수행하는 기능들을 호출할 수 있어야 합니다. 이를 위해서 LLM이 비정형화된 Text 대신 Text를 반환하도록 만들어 두어야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ecb88-d65d-49ea-b271-73a14f11e3fd",
   "metadata": {},
   "source": [
    "## 환경설정\n",
    "\n",
    "<img src=\"../resources/assets/langchain.png\" width=\"50%\">\n",
    "\n",
    "Langchain은 LLM을 활용한 애플리케이션 개발을 지원하는 강력한 프레임워크입니다. OpenAI, Anthropic, Azure, Google, Groq 등 다양한 LLM과 호환되며, 각 모델 별로 추가 라이브러리를 설치해야 합니다.\n",
    "\n",
    "먼저, Langchain과 Langchain OpenAI 라이브러리를 설치해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4d043-f94d-40d8-ba10-8feac34ee8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103b6e9-3c86-4a6b-a7a8-5ba2d16fb296",
   "metadata": {},
   "source": [
    "#### OpenAI API KEY 발급받기\n",
    "\n",
    "<img src=\"../resources/assets/openai-platform.png\" width=\"30%\">\n",
    "\n",
    "[OpenAI Platform:api-key](https://platform.openai.com/api-keys)에서 API key를 발급받을 수 있습니다. 아래 스크립트를 실행하면, `getpass.getpass`를 사용하여 API 키를 안전하게 입력받아서 `ChatOpenAI` 객체를 초기화합니다. ChatOpenAI은 우리가 사용하는 ChatGPT의 대화창을 API로 호출할 수 있도록 만든 객체입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f083aa-9891-4980-9855-ee256f1c3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "openai api-key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "api_key = getpass.getpass(\"openai api-key:\")\n",
    "llm = ChatOpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da18d4-8dfc-4cde-8bd1-47650ba4a6a1",
   "metadata": {},
   "source": [
    "## Langchain을 사용한 LLM 호출\n",
    "\n",
    "프로그래밍 관점에서 LLM은 텍스트 메시지를 입력받아 텍스트 메시지를 출력하는 함수입니다. \n",
    "\n",
    "````mermaid\n",
    "flowchart LR\n",
    "    input[입력:\\n안녕 LLM] == LLM ==> output[출력:\\n반가워 휴먼]\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d57a9-e937-41ac-a519-cca155a360eb",
   "metadata": {},
   "source": [
    "간단하게 \"안녕\"이라고 입력하면, 아래와 같이 ChatGPT를 호출 후, AIMessage를 반환합니다. \n",
    "\n",
    "AIMessage는 말그대로 AI가 만든 Message로, LLM의 출력 메시지를 뜻합니다. LLM에서는 AIMessage 외에도, SystemMessage와 HumanMessage가 더 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebcf47b4-0841-4654-9aaf-87bd2eeb5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83399f6a-119b-4e84-810b-2e37954f159c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"안녕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20358ecf",
   "metadata": {},
   "source": [
    "### 메시지 타입 이해: SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "LLM에서 메시지 타입은 크게 3가지 유형으로 나뉩니다.\n",
    "\n",
    "| 유형 | 역할 | 설명 |\n",
    "| --- | --- | --- |\n",
    "| SystemMessage | 대화의 맥락을 설정하고, 모델의 행동 지침을 제공 | 모델에게 특정 역할을 부여하거나, 대화의 규칙을 설정하는 데 사용  |\n",
    "| HumanMessage | 사용자가 모델에게 전달하는 입력 | 사용자가 모델에게 질문을 하거나 요청을 전달하는 데 사용 |\n",
    "| AIMessage | 모델이 생성한 응답 | 모델이 사용자에게 응답을 제공하는 데 사용 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd591cbc-670b-4f5c-ba65-77ee905bb65a",
   "metadata": {},
   "source": [
    "### SystemMessage과 HumanMessage\n",
    "\n",
    "SystemMessage를 통해, AI에게 특정한 역할과 행동 지침을 부여할 수 있습니다. 예를 들어, AI가 유저의 엄격한 도덕 선생님 역할을 맡도록 설정할 수 있습니다. 이렇게 만든 규칙 하에서 우리의 요청은 HumanMessage로 정의 후 호출하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1433244c-e4b4-4c16-86a2-e98966874333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요. 높임말을 사용해 주세요. \"안녕하세요\"라고 써주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 64, 'total_tokens': 96, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0ab8a495-a230-428a-8eca-05bfb017c9d1-0', usage_metadata={'input_tokens': 64, 'output_tokens': 32, 'total_tokens': 96})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"당신은 유저의 엄격한 도덕 선생님입니다. 유저가 높임말을 쓰도록 훈육해 주세요\"\n",
    ")\n",
    "input_message = HumanMessage(content=\"안녕\")\n",
    "\n",
    "llm.invoke([\n",
    "    system_message,\n",
    "    input_message\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a0bc0-d4bc-4406-a66a-80d63977448b",
   "metadata": {},
   "source": [
    "같은 인삿말이라도 SystemMessage이 어떻게 정했느냐에 따라, LLM은 서로 다르게 동작합니다. 이처럼, SystemMessage를 통해 AI의 역할과 응답 방식을 다양하게 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee99008c-6b4c-49a6-99f1-2eef039d2b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕! 반가워 😊 어떤 이야기를 나누고 싶어?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 52, 'total_tokens': 81, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3c7acd61-87b5-457f-87b4-b342238c7228-0', usage_metadata={'input_tokens': 52, 'output_tokens': 29, 'total_tokens': 81})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=\"당신은 유저의 동갑내기 친구야. 유저에게 반갑게 화답해줘.\"\n",
    ")\n",
    "\n",
    "input_message = HumanMessage(content=\"안녕\")\n",
    "\n",
    "llm.invoke([\n",
    "    system_message,\n",
    "    input_message\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6528f-2684-4025-a4c2-1052c314edf0",
   "metadata": {},
   "source": [
    "## 프롬프트를 템플릿화하기 \n",
    "\n",
    "프롬프트를 템플릿화하면 반복적인 작업을 쉽게 처리할 수 있습니다. **PromptTemplate**을 사용하면 프롬프트 내의 특정 부분을 변수로 대체하여 다양한 상황에 유연하게 대응할 수 있습니다. 이는 코드의 재사용성을 높이고, 유지보수를 용이하게 하며, 일관된 응답을 생성하는 데 큰 장점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7dbad-50bc-4064-9dce-76e891d511f6",
   "metadata": {},
   "source": [
    "### PromptTemplate의 장점\n",
    "\n",
    "- **재사용성**: 동일한 구조의 프롬프트를 여러 번 사용할 수 있어 효율적입니다.\n",
    "- **유연성**: 변수 부분을 통해 다양한 입력에 대응할 수 있습니다.\n",
    "- **일관성**: 일관된 프롬프트 구조를 유지하여 예측 가능한 AI 응답을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca3b89",
   "metadata": {},
   "source": [
    "다음은 프롬프트 템플릿을 구성하는 예시입니다.\n",
    "\n",
    "아래와 같은 프롬프트에서, SystemMessage에서 역할을 의미하는 `동갑내기 친구`와 HumanMessage에서의 유저 말만 매번 바뀐다고 생각해봅시다.\n",
    "\n",
    "````\n",
    "[system]\n",
    "당신은 유저의 동갑내기 친구야. 그 역할에 따라 대화해주세요.\n",
    "\n",
    "[human]\n",
    "안녕, 지금 뭐해?\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785fc3a7-002f-4c7d-a32c-58995c9ab7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\"당신은 유저의 {role}입니다.\")\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{message}\")\n",
    "\n",
    "input_template = ChatPromptTemplate(\n",
    "    messages=[system_message, human_message],\n",
    "    input_variables=[\"role\", \"message\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c5f7f-297e-4063-a605-6e4ce33fb1dd",
   "metadata": {},
   "source": [
    "이렇게 만든 템플릿으로 아래와 같이, 실제 프롬프트를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d7bbe8b-cf17-4460-bb48-22faa6494af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 유저의 동갑내기 친구입니다.\n",
      "Human: 반가워\n"
     ]
    }
   ],
   "source": [
    "print(input_template.format(role=\"동갑내기 친구\", message=\"반가워\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d9417e-f3b4-40b7-8f49-365e0d33f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 유저의 스승님입니다.\n",
      "Human: 숙제 안해왔어요..\n"
     ]
    }
   ],
   "source": [
    "print(input_template.format(role=\"스승님\", message=\"숙제 안해왔어요..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2afcb",
   "metadata": {},
   "source": [
    "## Langchain에서의 Chain\n",
    "\n",
    "Langchain의 **Chain**을 활용하면, 프롬프트 생성에서부터 LLM 호출까지의 일련의 과정을 하나의 파이프라인으로 연결할 수 있습니다. 이를 통해 코드의 가독성과 유지보수성을 크게 향상시킬 수 있습니다. Chain을 사용하면 각 단계를 독립적으로 관리할 수 있으며, 필요에 따라 쉽게 확장할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb52c0ea-884d-42ee-a7f7-c288eefc51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    input_template\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce96cd78-6569-4259-aecf-f3e93c0c0620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='숙제를 왜 안했나요? 어떤 이유가 있나요? 함께 이유를 알아보고 해결책을 찾아볼까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 37, 'total_tokens': 92, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-184ca0a0-2250-42bf-b9c3-d8596d46ec96-0', usage_metadata={'input_tokens': 37, 'output_tokens': 55, 'total_tokens': 92})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'role': \"선생님\", \"message\":\"숙제 안해왔어요..\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62b57c",
   "metadata": {},
   "source": [
    "위와 같이 작성하면 크게 아래와 같은 장점이 있습니다.\n",
    "\n",
    "- **가독성**: 복잡한 로직을 단순화하여 읽기 쉽게 만듭니다.\n",
    "- **모듈화**: 각 단계를 독립적으로 관리할 수 있어 유지보수가 용이합니다.\n",
    "- **확장성**: 새로운 기능을 쉽게 추가할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed46e6e-3830-416b-a0b9-3e54865bb343",
   "metadata": {},
   "source": [
    "## LLM의 어려움: 다루기 어려운 텍스트\n",
    "\n",
    "자연어는 인간이 이해하기 쉬운 형태이지만, 프로그래밍을 작성하는 입장에서는 다루기가 어렵습니다. 예를 들어 단순한 수학 계산을 요청하는 상황을 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95bbcc6-a7ad-435a-b56c-e6a3ed1c7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = HumanMessage(content=\"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c27a4b5-7a00-417d-a317-3a32f78d00a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x=1, y=2일 때, 2 * (3 * x + y * 5)는 다음과 같이 계산할 수 있습니다.\\n\\n2 * (3 * 1 + 2 * 5)\\n= 2 * (3 + 10)\\n= 2 * 13\\n= 26\\n\\n따라서, 2 * (3 * x + y * 5)는 26입니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = llm.invoke([input_message])\n",
    "output0.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ea1d3c-a7e4-4a2f-bbfc-495534dcc02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = 1, y = 2를 대입하면,\\n\\n2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26\\n\\n따라서, 2 * (3 * x + y * 5)는 26입니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1 = llm.invoke([input_message])\n",
    "output1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43001cee-992e-46e2-82e4-83ee5df019ad",
   "metadata": {},
   "source": [
    "이렇게 LLM은 다양한 형태로 응답합니다. 이런 게 다양한 형태의 텍스트에서 우리가 원하는 정답을 도출하는 것은 매우 까다롭습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e030cfa-15a6-4044-9857-35ca497a37d8",
   "metadata": {},
   "source": [
    "### 응답값을 구조화하기\n",
    "\n",
    "LLM이 반환하는 다양한 형태의 텍스트 응답을 효과적으로 처리하기 위해, 응답값을 구조화할 필요가 있습니다. 예를 들어, 단순한 수학 계산을 요청할 때, LLM이 JSON 형식으로 응답하도록 지시할 수 있습니다.\n",
    "\n",
    "예를들어, chatGPT가 아래와 같이 응답한다면 어떨까요? \n",
    "\n",
    "````json\n",
    "{\n",
    "   \"result\": 26,\n",
    "   \"description\":\"2*(3 * x + y * 5) = 2*(3*1 + 2*5) = 2*(3 + 10) = 2*13 = 26\\n\\n따라서, 2*(3 * x + y * 5)의 값은 26입니다.\" \n",
    "}\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084b233-b395-4865-9714-09efd89efbc3",
   "metadata": {},
   "source": [
    "우리는 훨씬 더 편하게 값을 처리할 수 있을 것입니다. 이렇게 출력값이 나오기 위해서는, 우리는 LLM에게 **어떻게 출력해야 하는지를** 지시해야 합니다. \n",
    "보통 아래와 같은 지시문을 `SystemMessage`에 담아서 호출합니다.\n",
    "\n",
    "````\n",
    "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"result\": float  // The numerical result of the calculation\n",
    "\t\"description\": string  //description of the calculation process\n",
    "}\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "539efcbe-2463-4db7-9bdb-29443f163acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"description\": \"계산 과정: 2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26\",\n",
      "\t\"result\": 26\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction = (\n",
    "'The output should be a markdown code snippet formatted in the following schema,' \n",
    "'including the leading and trailing \"```json\" and \"```\":\\n\\n'\n",
    "'```json\\n'\n",
    "'{\\n'\n",
    "'\t\"description\": string // description of the calculation process \\n'\n",
    "'\t\"result\": float   // The numerical result of the calculation \\n'    \n",
    "\"}\\n\"\n",
    "\"```\\n\"\n",
    ")\n",
    "\n",
    "input_message = HumanMessage(content=\"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\")\n",
    "output = llm.invoke([SystemMessage(instruction), input_message])\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef239b-16eb-4d2f-9fba-d88cb2c3b93e",
   "metadata": {},
   "source": [
    "### OutputParser을 활용한 파싱\n",
    "\n",
    "Langchain의 `StructuredOutputParser`를 사용하면, 원하는 형식의 응답을 쉽게 파싱할 수 있습니다. 이를 통해 응답 데이터를 체계적으로 처리하고 활용할 수 있습니다.\n",
    "\n",
    "다음은 `StructuredOutputParser`를 설정하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9010d2-d553-47c1-bfd6-98aeba48d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='result', description='The numerical result of the calculation', type='float'), ResponseSchema(name='description', description='description of the calculation process', type='string')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"result\", description=\"The numerical result of the calculation\", type='float'),\n",
    "    ResponseSchema(name=\"description\", description=\"description of the calculation process\", type='string'),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser(response_schemas=response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09ce31-02e0-4864-aa3f-8b12d82647b9",
   "metadata": {},
   "source": [
    "파서에서 원하는 형태의 응답값을 받기 위한 지침은 아래와 같이 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185d1307-8f8d-432b-8bff-efc43162e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"result\": float  // The numerical result of the calculation\n",
      "\t\"description\": string  // description of the calculation process\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "inst = output_parser.get_format_instructions()\n",
    "print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b96b6b-bc8d-40bb-beb3-51d7beed498c",
   "metadata": {},
   "source": [
    "이제 이 지침을 SystemMessage에 담아 LLM에게 전달하면, 구조화된 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796c2695-dbd3-4e44-a764-6983a8535d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=inst)\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{message}\")\n",
    "\n",
    "input_template = ChatPromptTemplate(\n",
    "    messages=[system_message, human_message],\n",
    "    input_variables=[\"message\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc4d310-88cf-4ca8-a4bb-7308b461e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"result\": 31.0,\n",
      "\t\"description\": \"계산 과정: 2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = (\n",
    "    input_template\n",
    "    | llm\n",
    ").invoke({\"message\": \"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\"})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c477281-282d-421f-9f87-c31c82807a31",
   "metadata": {},
   "source": [
    "`StructuredOutputParser`를 사용하여 응답을 파싱하면, Dictionary 형태로 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "887708c7-4796-42af-8534-30f5dbbb9d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 31.0,\n",
       " 'description': '계산 과정: 2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = output_parser.invoke(output.content)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd148b-7b00-4b1b-937b-899321896567",
   "metadata": {},
   "source": [
    "output_parser도 Langchain의 chain을 통해 아래와 같이 처리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed53b7ed-df59-40c9-afc1-503e39fa5f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 29.0,\n",
       " 'description': '계산 순서에 따라 (3 * 1 + 2 * 5) = 13이 되고, 이후 2 * 13 = 26을 계산하면 최종 결과는 29.0이 됩니다.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    input_template\n",
    "    | llm\n",
    "    | output_parser\n",
    ").invoke({\"message\": \"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ecc48ae-885b-4ab1-a7e2-20b63b3eed2b",
   "metadata": {},
   "source": [
    "### 내장된 StructuredOutput 사용하기\n",
    "\n",
    "최근 대부분 LLM 모델들은 `StructuredOutput`을 내장하여 출시하고 있습니다. 위와 같이 프롬프트 생성하고, 파서를 별도로 두지 않고도 LLM 내부에서 아래와 같이 간결하게 출력할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fdd2cbd1-d9e5-4353-ad72-80f59321b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CalculationResponse(BaseModel):\n",
    "    \"\"\" the numerical result and description of the calcuation \"\"\"\n",
    "    result: float = Field(description=\"the numerical result of the calculation\")\n",
    "    description: str = Field(description=\"The description of the calculation process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dbf019da-95e6-402e-8ed9-26020bca537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalculationResponse(result=31.0, description='계산과정: 2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(CalculationResponse)\n",
    "structured_llm.invoke(\"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5518a5-b03b-49ea-a776-fb900d63680b",
   "metadata": {},
   "source": [
    "하지만 위와 같이 응답값을 강제하는 경우에는 아래처럼 일반적인 대화를 못한다는 한계가 존재합니다. 아래와 같이 모델이 실패합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "26a2bec5-572a-4fce-a94d-41570536f064",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for CalculationResponse\nresult\n  Input should be a valid number [type=float_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/float_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(CalculationResponse)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstructured_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m안녕? 반가워, 뭐하니?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/runnables/base.py:2879\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2878\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2879\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:183\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/runnables/base.py:1786\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1783\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1784\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1785\u001b[0m         Output,\n\u001b[0;32m-> 1786\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1794\u001b[0m     )\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1796\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:184\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 184\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    188\u001b[0m             config,\n\u001b[1;32m    189\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m             config,\n\u001b[1;32m    196\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/output_parsers/openai_tools.py:296\u001b[0m, in \u001b[0;36mPydanticToolsParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_tool_only:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_objects[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m pydantic_objects \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/langchain_core/output_parsers/openai_tools.py:291\u001b[0m, in \u001b[0;36mPydanticToolsParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool arguments must be specified as a dict, received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         )\n\u001b[0;32m--> 291\u001b[0m     pydantic_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mname_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pydantic/main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for CalculationResponse\nresult\n  Input should be a valid number [type=float_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/float_type"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(CalculationResponse)\n",
    "structured_llm.invoke(\"안녕? 반가워, 뭐하니?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657aef5-b936-455a-8e15-f0cd928f0fa8",
   "metadata": {},
   "source": [
    "이를 보완하기 위해, 필요에 따라 응답 형태를 선택할 수 있도록 아래와 같이 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c7d097e1-fe34-4e0a-9066-b4a4554f8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"Respond in a conversational manner. \"\"\"\n",
    "    response: str = Field(description=\"A conversational response to the user's query\")\n",
    "\n",
    "class UnionResponse(BaseModel):\n",
    "    output: Union[CalculationResponse, ConversationalResponse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7724b6c5-3d41-4376-bb2f-15f50d27da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_llm = llm.with_structured_output(UnionResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79beae3-fe3d-4aa5-b25f-f0b8f53d9d23",
   "metadata": {},
   "source": [
    "해당 모델을 통해, 수학 문제를 풀때는 수학 문제에 맞는 형태의 응답값을 도출하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "28d76c0d-8420-4819-b075-f4151d81bcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionResponse(output=CalculationResponse(result=31.0, description='계산 과정은 다음과 같습니다: 2 * (3 * 1 + 2 * 5) = 2 * (3 + 10) = 2 * 13 = 26'))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_llm.invoke(\"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17d1ab-323d-4859-8ffd-fe169bc1fe59",
   "metadata": {},
   "source": [
    "대화일 때에는 대화형태에 맞도록 응답할 수 있도록 행동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e09ed757-de21-4fb4-a8b7-cd47422e5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionResponse(output=ConversationalResponse(response='안녕하세요! 저는 여기 있어요. 당신은 뭐 하고 있나요?'))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_llm.invoke(\"안녕? 반가워, 뭐하니?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00069c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "### 마무리\n",
    "\n",
    "이번 글에서는 Langchain과 LLM을 활용하여 AI 에이전트를 개발하는 과정을 살펴보았습니다. 프롬프트 템플릿화, 메시지 타입 이해, 출력 파서를 통한 응답값 구조화 등을 통해 보다 효과적이고 구조화된 AI 에이전트를 만드는 방법을 배웠습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

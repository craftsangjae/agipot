{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e93f7e6-3f14-4dee-aee4-8454b7fb1fb8",
   "metadata": {},
   "source": [
    "# LLM을 활용하여 AI Agent 만들기 (1) StructuredOutputParser을 통한 응답값 구조화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427b9d5-b6ea-4da5-984b-d63b728b3882",
   "metadata": {},
   "source": [
    "#### Reference : [how-to-use-structuredoutputparser-with-langchain](https://medium.com/@meta_heuristic/how-to-use-structuredoutputparser-with-langchain-6caaa486830)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ecb88-d65d-49ea-b271-73a14f11e3fd",
   "metadata": {},
   "source": [
    "#### 환경설정\n",
    "\n",
    "langchain은 LLM을 활용한 어플리케이션 개발 시 사용되는 프레임워크입니다. langchain_openai는 openAI와 연동을 위해 별도로 설치해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e4d043-f94d-40d8-ba10-8feac34ee8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103b6e9-3c86-4a6b-a7a8-5ba2d16fb296",
   "metadata": {},
   "source": [
    "#### OpenAI API KEY 발급받기\n",
    "\n",
    "<img src=\"../resources/assets/openai-platform.png\" width=\"30%\">\n",
    "\n",
    "[OpenAI Platform:api-key](https://platform.openai.com/api-keys)에서 API key를 발급받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f083aa-9891-4980-9855-ee256f1c3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a2bb7da-3c16-4c73-86a4-7fc56b8f576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "openai api-key: ········\n"
     ]
    }
   ],
   "source": [
    "api_key = getpass.getpass(\"openai api-key:\")\n",
    "llm = ChatOpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da18d4-8dfc-4cde-8bd1-47650ba4a6a1",
   "metadata": {},
   "source": [
    "### LLM을 호출하기\n",
    "\n",
    "프로그래밍 관점에서 보았을 때, LLM은 텍스트 메시지를 입력받아 텍스트 메시지를 출력하는 함수입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebcf47b4-0841-4654-9aaf-87bd2eeb5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8f691dea-0018-42f8-a7c6-0adda27c8c25-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"안녕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aee972-68b3-4247-b1cb-864a474b4518",
   "metadata": {},
   "source": [
    "LLM에서 메시지 타입은 크게 3가지 유형으로 나뉩니다.\n",
    "\n",
    "| 유형 | 역할 | 설명 |\n",
    "| --- | --- | --- |\n",
    "| SystemMessage | 대화의 맥락을 설정하고, 모델의 행동 지침을 제공 | 모델에게 특정 역할을 부여하거나, 대화의 규칙을 설정하는 데 사용  |\n",
    "| HumanMessage | 사용자가 모델에게 전달하는 입력 | 사용자가 모델에게 질문을 하거나 요청을 전달하는 데 사용 |\n",
    "| AIMessage | 모델이 생성한 응답 | 모델이 사용자에게 응답을 제공하는 데 사용 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd591cbc-670b-4f5c-ba65-77ee905bb65a",
   "metadata": {},
   "source": [
    "아래와 같이 AI에게 특정한 역할과 행동 지침을 부여할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1433244c-e4b4-4c16-86a2-e98966874333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c8fa803-05e4-4491-9491-cc1f8d647042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"안녕하세요. 높임말을 사용해 주시기 바랍니다. 예를 들어 '안녕하세요'라고 쓰시면 좋겠습니다. 감사합니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 64, 'total_tokens': 117, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a9d6a26a-bc8f-4d7f-9b19-de6b5e509303-0', usage_metadata={'input_tokens': 64, 'output_tokens': 53, 'total_tokens': 117})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = SystemMessage(content=\"당신은 유저의 엄격한 도덕 선생님입니다. 유저가 높임말을 쓰도록 훈육해 주세요\")\n",
    "\n",
    "input_message = HumanMessage(content=\"안녕\")\n",
    "\n",
    "llm.invoke([\n",
    "    system_message,\n",
    "    input_message\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a0bc0-d4bc-4406-a66a-80d63977448b",
   "metadata": {},
   "source": [
    "이렇듯, 같은 인삿말이라도 system_message이 어떻게 정했느냐에 따라, LLM은 서로 다르게 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee99008c-6b4c-49a6-99f1-2eef039d2b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕! 반가워 😊 함께 재미있는 대화를 나눠보자! 어떤 이야기를 나누고 싶어?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 52, 'total_tokens': 101, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-16c0125f-77ba-4c2d-9d5a-8a59c961011b-0', usage_metadata={'input_tokens': 52, 'output_tokens': 49, 'total_tokens': 101})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = SystemMessage(content=\"당신은 유저의 동갑내기 친구야. 유저에게 반갑게 화답해줘.\")\n",
    "\n",
    "input_message = HumanMessage(content=\"안녕\")\n",
    "\n",
    "llm.invoke([\n",
    "    system_message,\n",
    "    input_message\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed46e6e-3830-416b-a0b9-3e54865bb343",
   "metadata": {},
   "source": [
    "### LLM의 어려움: 다루기 어려운 텍스트\n",
    "\n",
    "자연어는 인간이 이해하기 쉬운 형태이지만, 프로그래밍을 작성하는 입장에서는 다루기가 어렵습니다. 예를 들어 단순한 수학 계산을 요청하는 상황을 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d95bbcc6-a7ad-435a-b56c-e6a3ed1c7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = HumanMessage(content=\"x=1, y=2일 때, 2 * (3 * x + y * 5)는 얼마일까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c27a4b5-7a00-417d-a317-3a32f78d00a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 식을 계산하면 다음과 같습니다:\\n\\n2*(3 * x + y * 5) = 2*(3*1 + 2*5) = 2*(3 + 10) = 2*13 = 26\\n\\n따라서, 2*(3 * x + y * 5)의 값은 26입니다.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = llm.invoke([input_message])\n",
    "output0.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26ea1d3c-a7e4-4a2f-bbfc-495534dcc02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2*(3 * x + y * 5) = 2*(3 * 1 + 2 * 5) = 2*(3 + 10) = 2*13 = 26\\n\\n따라서 2*(3 * x + y * 5)는 26입니다.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1 = llm.invoke([input_message])\n",
    "output1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43001cee-992e-46e2-82e4-83ee5df019ad",
   "metadata": {},
   "source": [
    "이렇게 LLM은 다양한 형태로 응답합니다. 이런 게 다양한 형태의 텍스트에서 우리가 원하는 정답을 도출하는 것은 매우 까다롭습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e030cfa-15a6-4044-9857-35ca497a37d8",
   "metadata": {},
   "source": [
    "### 응답값을 구조화하기\n",
    "\n",
    "예를들어, chatGPT가 아래와 같이 응답한다면 어떨까요? \n",
    "\n",
    "````json\n",
    "{\n",
    "   \"result\": 26,\n",
    "   \"description\":\"2*(3 * x + y * 5) = 2*(3*1 + 2*5) = 2*(3 + 10) = 2*13 = 26\\n\\n따라서, 2*(3 * x + y * 5)의 값은 26입니다.\" \n",
    "}\n",
    "````\n",
    "\n",
    "우리는 훨씬 더 편하게 값을 처리할 수 있을 것입니다. 이렇게 출력값을 나오도록 `SystemMessage`을 통해 LLM에게 알려주면 됩니다.\n",
    "\n",
    "````\n",
    "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"result\": float  // The numerical result of the calculation\n",
    "\t\"description\": string  //description of the calculation process\n",
    "}\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "539efcbe-2463-4db7-9bdb-29443f163acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"description\": \"Calculate the result of the expression 2*(3*x + y*5) with x=1 and y=2\",\n",
      "\t\"result\": 28.0\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction = (\n",
    "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n'\n",
    "'```json\\n'\n",
    "'{\\n'\n",
    "'\t\"description\": string // description of the calculation process \\n'\n",
    "'\t\"result\": float   // The numerical result of the calculation \\n'    \n",
    "\"}\\n\"\n",
    "\"```\\n\"\n",
    ")\n",
    "\n",
    "output = llm.invoke([\n",
    "    SystemMessage(instruction),\n",
    "    input_message]\n",
    ")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c139e31-6715-431c-9478-03f00c7087bd",
   "metadata": {},
   "source": [
    "이렇게 훨씬 구조화되어서 응답값이 반환됩니다. `Langchain`에서는 이런 작업들을 도와줄 OutputParser가 존재합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c9010d2-d553-47c1-bfd6-98aeba48d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='result', description='The numerical result of the calculation', type='float'), ResponseSchema(name='description', description='description of the calculation process', type='string')])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"result\", description=\"The numerical result of the calculation\", type='float'),\n",
    "    ResponseSchema(name=\"description\", description=\"description of the calculation process\", type='string'),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser(response_schemas=response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09ce31-02e0-4864-aa3f-8b12d82647b9",
   "metadata": {},
   "source": [
    "파서에서 원하는 형태의 응답값을 받기 위한 지침은 아래와 같이 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "185d1307-8f8d-432b-8bff-efc43162e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"result\": float  // The numerical result of the calculation\n",
      "\t\"description\": string  // description of the calculation process\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "inst = output_parser.get_format_instructions()\n",
    "print(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bc4d310-88cf-4ca8-a4bb-7308b461e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"result\": 32.0,\n",
      "\t\"description\": \"Calculate 3 * x = 3 * 1 = 3 and y * 5 = 2 * 5 = 10. Then, calculate 2 * (3 + 10) = 2 * 13 = 26.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke([SystemMessage(inst), input_message])\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "887708c7-4796-42af-8534-30f5dbbb9d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 32.0,\n",
       " 'description': 'Calculate 3 * x = 3 * 1 = 3 and y * 5 = 2 * 5 = 10. Then, calculate 2 * (3 + 10) = 2 * 13 = 26.'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = output_parser.invoke(output.content)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd148b-7b00-4b1b-937b-899321896567",
   "metadata": {},
   "source": [
    "훨씬 더 구조화된 답변을 받을 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6cc03a53-8532-4fdf-b4d7-c13c27dc76b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.0,\n",
       " 'Calculate 3 * x = 3 * 1 = 3 and y * 5 = 2 * 5 = 10. Then, calculate 2 * (3 + 10) = 2 * 13 = 26.')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['result'], r['description']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
